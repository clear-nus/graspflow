{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "14206d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a7f6402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2array(x, delimter=' ', dtype=float):\n",
    "    '''\n",
    "    converts string of [23 21 0 12] to numpy array\n",
    "    '''\n",
    "    xs = x.strip()[1:-1].split(delimter)\n",
    "    new_x = []\n",
    "    for _x in xs:\n",
    "        new_x.append(dtype(_x))\n",
    "    return np.array(new_x)\n",
    "\n",
    "def load_isaac_results(experiment, prefix, full_exeriment=True, experiments_dir = '../experiments'):\n",
    "    '''\n",
    "    Loads isaac data regardless of what experiment (full or gripper only).\n",
    "    '''\n",
    "    \n",
    "    cats = []\n",
    "    indcs = []\n",
    "    env_nums = []\n",
    "    labels = []\n",
    "    mi_scores = []\n",
    "\n",
    "    if full_exeriment:\n",
    "        fname = f'{experiments_dir}/generated_grasps_experiment{experiment}/Full Experiment {experiment} log {prefix}.txt'\n",
    "        \n",
    "    else:\n",
    "        fname = f'{experiments_dir}/generated_grasps_experiment{experiment}/Experiment {experiment} log {prefix}.txt'\n",
    "\n",
    "        \n",
    "    fp = open(fname)\n",
    "    all_data_txt = fp.read().split('\\n')\n",
    "    fp.close()\n",
    "    \n",
    "\n",
    "    for line in all_data_txt:\n",
    "        \n",
    "        if len(line) < 4:\n",
    "            continue\n",
    "        \n",
    "        if full_exeriment:\n",
    "            cat, idx, env_num, label, mi_score = line.split('=')\n",
    "        else:\n",
    "            cat, idx, env_num, label = line.split('=')\n",
    "        cats.append(cat)\n",
    "        indcs.append(int(idx))\n",
    "        env_nums.append(int(env_num))\n",
    "        labels.append(str2array(label, dtype=int))\n",
    "        if full_exeriment:\n",
    "            mi_scores.append(str2array(mi_score[:-1], dtype=float))\n",
    "        else:\n",
    "            mi_scores.append(np.zeros_like(labels[-1]))\n",
    "                \n",
    "    return cats, indcs, env_nums, labels, mi_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def construct_df(experiment, sampler, prefix, experiments_dir, full_exeriment=True):\n",
    "    \n",
    "    prefix_sampler = f'{sampler}_N_N_N'\n",
    "\n",
    "    # load isaac data\n",
    "    cats, indcs, env_nums, labels, mi_scores = load_isaac_results(experiment, prefix=prefix, full_exeriment=full_exeriment)\n",
    "    _, _, _, sampler_labels, sampler_mi_scores = load_isaac_results(experiment, prefix=prefix_sampler, full_exeriment=full_exeriment)\n",
    "\n",
    "    # load npz data and sort\n",
    "    init_scores = []\n",
    "    final_scores = []\n",
    "    exec_times = []\n",
    "    init_robot_scores = []\n",
    "    final_robot_scores = []\n",
    "\n",
    "    original_scores = [] \n",
    "    sample_times = []\n",
    "\n",
    "    for i in range(len(cats)):\n",
    "        data = np.load(f'{experiments_dir}/generated_grasps_experiment{experiment}/{cats[i]}{indcs[i]:003}_{sampler}.npz')\n",
    "        init_score = data[f'{prefix}_init_scores'][env_nums[i]]\n",
    "        sorted_indcs = np.argsort(init_score)\n",
    "        labels[i] = labels[i][sorted_indcs]\n",
    "        mi_scores[i] = mi_scores[i][sorted_indcs]\n",
    "        init_scores.append(init_score[sorted_indcs])\n",
    "        # print(i,data[f'{prefix}_time'][env_nums[i]])\n",
    "        exec_times.append(data[f'{prefix}_time'][env_nums[i]])\n",
    "        final_scores.append( data[f'{prefix}_scores'][env_nums[i]][sorted_indcs])\n",
    "        init_robot_scores.append( data[f'{prefix}_init_robot_scores'][env_nums[i]][sorted_indcs] )\n",
    "        final_robot_scores.append( data[f'{prefix}_robot_scores'][env_nums[i]][sorted_indcs] )\n",
    "        sample_times.append(data[f'{prefix_sampler}_time'][env_nums[i]])\n",
    "        original_scores.append( data[f'{prefix_sampler}_original_scores'][env_nums[i]][sorted_indcs])\n",
    "        sampler_labels[i] = sampler_labels[i][sorted_indcs]\n",
    "        sampler_mi_scores[i] = sampler_mi_scores[i][sorted_indcs]\n",
    "\n",
    "    # create big dataframe to work with ease\n",
    "    num_grasps = len(labels[0])\n",
    "    num_envs = len(np.unique(env_nums))\n",
    "    \n",
    "    if sampler == 'gpd':\n",
    "        sample_times = np.repeat(sample_times, num_grasps)\n",
    "    elif sampler == 'graspnet':\n",
    "        sample_times = np.array(sample_times).flatten()\n",
    "    \n",
    "    df_data = {\n",
    "        'cat': np.repeat(cats, num_grasps),\n",
    "        'idx': np.repeat(indcs, num_grasps),\n",
    "        # 'labels': np.repeat(env_nums, env_nums),\n",
    "        'env_num': np.repeat(env_nums, num_grasps),\n",
    "        'labels': np.concatenate(labels),\n",
    "        'mi_score': np.concatenate(mi_scores),\n",
    "        'init_scores': np.concatenate(init_scores),\n",
    "        'final_scores': np.concatenate(final_scores),\n",
    "        'init_robot_scores': np.concatenate(init_robot_scores),\n",
    "        'final_robot_scores': np.concatenate(final_robot_scores),\n",
    "        'exec_times': np.repeat(exec_times, num_grasps),\n",
    "        'original_scores': np.concatenate(original_scores),\n",
    "        'sample_times': sample_times,\n",
    "        'sampler_labels': np.concatenate(sampler_labels),\n",
    "        'sampler_mi_scores': np.concatenate(sampler_mi_scores)\n",
    "    }\n",
    "    \n",
    "    print(df_data['exec_times'].shape, df_data['sample_times'].shape)\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "\n",
    "    return df, num_grasps, num_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cb7b66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cats, indcs, env_nums, labels, mi_scores = load_isaac_results(28, prefix=\"gpd_N_N_N\", full_exeriment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "bef2b8ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420,) (420,)\n"
     ]
    }
   ],
   "source": [
    "experiments_dir='../experiments'\n",
    "sampler='graspnet'\n",
    "prefix = f\"{sampler}_SE_GraspFlow_Theta\"\n",
    "experiment=28\n",
    "\n",
    "df, num_grasps, num_envs = construct_df(experiment, sampler, prefix, experiments_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0413791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>idx</th>\n",
       "      <th>env_num</th>\n",
       "      <th>labels</th>\n",
       "      <th>mi_score</th>\n",
       "      <th>init_scores</th>\n",
       "      <th>final_scores</th>\n",
       "      <th>init_robot_scores</th>\n",
       "      <th>final_robot_scores</th>\n",
       "      <th>exec_times</th>\n",
       "      <th>original_scores</th>\n",
       "      <th>sample_times</th>\n",
       "      <th>sampler_labels</th>\n",
       "      <th>sampler_mi_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottle</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.079198</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.965913</td>\n",
       "      <td>0.026835</td>\n",
       "      <td>0.574927</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bottle</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088556</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.965913</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.574927</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bottle</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.831182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.965913</td>\n",
       "      <td>0.338960</td>\n",
       "      <td>0.574927</td>\n",
       "      <td>4</td>\n",
       "      <td>0.041982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bottle</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065774</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.983109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.965913</td>\n",
       "      <td>0.097442</td>\n",
       "      <td>0.574927</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bottle</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.097056</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.904337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.965913</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.574927</td>\n",
       "      <td>4</td>\n",
       "      <td>0.097982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat  idx  env_num  labels  mi_score  init_scores  final_scores  \\\n",
       "0  bottle    3        0       4  0.014518     0.000002      0.079198   \n",
       "1  bottle    3        0       3  0.088556     0.000025      0.000028   \n",
       "2  bottle    3        0       1  0.044350     0.000473      0.831182   \n",
       "3  bottle    3        0       1  0.065774     0.001095      0.983109   \n",
       "4  bottle    3        0       4  0.097056     0.002145      0.904337   \n",
       "\n",
       "   init_robot_scores  final_robot_scores  exec_times  original_scores  \\\n",
       "0           0.999904                 1.0    4.965913         0.026835   \n",
       "1           1.000000                 1.0    4.965913         0.000172   \n",
       "2           1.000000                 1.0    4.965913         0.338960   \n",
       "3           1.000000                 1.0    4.965913         0.097442   \n",
       "4           1.000000                 1.0    4.965913         0.019830   \n",
       "\n",
       "   sample_times  sampler_labels  sampler_mi_scores  \n",
       "0      0.574927               2           0.015925  \n",
       "1      0.574927               3           0.087002  \n",
       "2      0.574927               4           0.041982  \n",
       "3      0.574927               1           0.069279  \n",
       "4      0.574927               4           0.097982  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "273694a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial classifier score: 0.17810329530789115\n",
      "After refinement score: 0.6632512327994846\n",
      "Initial Robot Classifier score: 0.9761695951858063\n",
      "Final Robot Classifier score: 0.9952258785565697\n",
      "Average refinement time: 4.57529480116708 (0.4885579125919171)\n",
      "Init Success Rate: 104\n",
      "Final Success Rate: 241\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial classifier score: {df.init_scores.mean()}')\n",
    "print(f'After refinement score: {df.final_scores.mean()}')\n",
    "print(f'Initial Robot Classifier score: {df.init_robot_scores.mean()}')\n",
    "print(f'Final Robot Classifier score: {df.final_robot_scores.mean()}')\n",
    "print(f'Average refinement time: {df.exec_times.mean()} ({df.exec_times.std()})')\n",
    "\n",
    "num_unique_cats = len(df.cat.unique())\n",
    "init_success_rate = df.loc[df.sampler_labels == 1, 'sampler_labels'].sum()#/(num_grasps*num_envs*num_unique_cats)\n",
    "print(f'Init Success Rate: {init_success_rate}')\n",
    "final_success_rate = df.loc[df.labels == 1, 'labels'].sum()#/(num_grasps*num_envs*num_unique_cats)\n",
    "print(f'Final Success Rate: {final_success_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0dccdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment=9\n",
    "# experiments_dir='../experiments'\n",
    "# sampler='gpd'\n",
    "# prefix = f\"{sampler}_S_GraspFlow_Euler\"\n",
    "\n",
    "# df, num_grasps, num_envs = construct_df(experiment, sampler, prefix, experiments_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077919a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Initial classifier score: {df.init_scores.mean()}')\n",
    "# print(f'After refinement score: {df.final_scores.mean()}')\n",
    "# print(f'Initial Robot Classifier score: {df.init_robot_scores.mean()}')\n",
    "# print(f'Final Robot Classifier score: {df.final_robot_scores.mean()}')\n",
    "# print(f'Average refinement time: {df.exec_times.mean()} ({df.exec_times.std()})')\n",
    "\n",
    "# num_unique_cats = len(df.cat.unique())\n",
    "# final_success_rate = df.loc[df.labels == 1, 'labels'].sum()/(num_grasps*num_envs*num_unique_cats)\n",
    "# print(f'Final Success Rate: {final_success_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10fb747",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for experiment in range(9,18):\n",
    "    print(f'-------------------------EXPERIMENT {experiment}---------------------------')\n",
    "    experiments_dir='../experiments'\n",
    "    sampler='gpd'\n",
    "    prefix = f\"{sampler}_S_GraspFlow_Euler\"\n",
    "\n",
    "    df, num_grasps, num_envs = construct_df(experiment, sampler, prefix, experiments_dir)\n",
    "\n",
    "    print(f'Initial classifier score: {df.init_scores.mean()}')\n",
    "    print(f'After refinement score: {df.final_scores.mean()}')\n",
    "    print(f'Initial Robot Classifier score: {df.init_robot_scores.mean()}')\n",
    "    print(f'Final Robot Classifier score: {df.final_robot_scores.mean()}')\n",
    "    print(f'Average refinement time: {df.exec_times.mean()} ({df.exec_times.std()})')\n",
    "\n",
    "    num_unique_cats = len(df.cat.unique())\n",
    "    init_success_rate = df.loc[df.sampler_labels == 1, 'sampler_labels'].sum()#/(num_grasps*num_envs*num_unique_cats)\n",
    "    print(f'Init Success Rate: {init_success_rate}')\n",
    "    final_success_rate = df.loc[df.labels == 1, 'labels'].sum()#/(num_grasps*num_envs*num_unique_cats)\n",
    "    print(f'Final Success Rate: {final_success_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f09430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, num_grasps, num_envs = construct_df(18, \"gpd\", 'gpd_S_GraspFlow_Euler', experiments_dir)\n",
    "df['success'] = df.apply(lambda row: 1 if row.labels==1 else 0, axis=1)\n",
    "df['init_success'] = df.apply(lambda row: 1 if row.sampler_labels==1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c951054",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial classifier score: {df.init_scores.mean()}')\n",
    "print(f'After refinement score: {df.final_scores.mean()}')\n",
    "print(f'Initial Robot Classifier score: {df.init_robot_scores.mean()}')\n",
    "print(f'Final Robot Classifier score: {df.final_robot_scores.mean()}')\n",
    "print(f'Average refinement time: {df.exec_times.mean()} ({df.exec_times.std()})')\n",
    "print(f'Average sampling time: {df.sample_times.mean()} ({df.sample_times.std()})')\n",
    "\n",
    "num_unique_items = df.groupby(['cat', 'idx']).count().shape[0]\n",
    "init_success_rate = df.loc[df.sampler_labels == 1, 'sampler_labels'].sum()/(num_grasps*num_envs*num_unique_items)\n",
    "print(f'Init Success Rate: {init_success_rate}')\n",
    "final_success_rate = df.loc[df.labels == 1, 'labels'].sum()/(num_grasps*num_envs*num_unique_items)\n",
    "print(f'Final Success Rate: {final_success_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47231b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df[['cat', 'idx', 'init_scores', 'final_scores', 'init_success', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7805a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df_table.groupby(['cat', 'idx']).agg({'init_scores': [np.mean],\n",
    "                                    'final_scores': [np.mean],\n",
    "                                     'init_success': [np.sum],\n",
    "                                     'success': [np.sum]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\n",
    "    'gpd_S_GraspFlow_Euler',\n",
    "    'gpd_S_GraspFlow_Theta',\n",
    "    'gpd_S_GraspFlow_SO3',\n",
    "    'gpd_SE_GraspFlow_Theta',\n",
    "    'gpd_S_graspnet_Euler',\n",
    "    'gpd_S_metropolis_Euler'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1d21b",
   "metadata": {},
   "source": [
    "Outline\n",
    "1. Overall statistics\n",
    "2. Breakdown by prefixes and objects\n",
    "3. Cumulative plot\n",
    "4. Breakdown of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_experiment=False\n",
    "all_dfs = []\n",
    "for prefix in prefixes:\n",
    "    df, num_grasps, num_envs = construct_df(18, \"gpd\", prefix, experiments_dir, full_experiment)\n",
    "    df['success'] = df.apply(lambda row: 1 if row.labels==1 else 0, axis=1)\n",
    "    df['init_success'] = df.apply(lambda row: 1 if row.sampler_labels==1 else 0, axis=1)\n",
    "    df = df.assign(prefix=prefix)\n",
    "    all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3cb3d",
   "metadata": {},
   "source": [
    "#### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why GrapsFlow poor respect to graspnet method?\n",
    "df_table = df[['prefix','init_scores', 'final_scores', 'success', 'init_success']]\n",
    "\n",
    "df_table = df_table.groupby(['prefix']).agg({'init_scores': [np.mean],\n",
    "                                    'final_scores': [np.mean],\n",
    "                                     'init_success': [np.sum],\n",
    "                                     'success': [np.sum]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why GrapsFlow poor respect to graspnet method?\n",
    "df_table = df[['prefix', 'cat', 'idx', 'init_scores', 'final_scores', 'success', 'init_success']]\n",
    "\n",
    "df_table = df[(df.prefix == 'gpd_S_GraspFlow_Euler') | (df.prefix == 'gpd_S_graspnet_Euler')]\n",
    "df_table = df_table.groupby(['prefix', 'cat', 'idx']).agg({'init_scores': [np.mean],\n",
    "                                     'final_scores': [np.mean],\n",
    "                                     'init_success': [np.sum],\n",
    "                                     'success': [np.sum]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d136c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why GrapsFlow poor respect to graspnet method?\n",
    "df_table = df[['prefix', 'cat', 'idx', 'init_scores', 'final_scores', 'success', 'init_success']]\n",
    "\n",
    "df_table = df[(df.prefix == 'gpd_S_GraspFlow_Theta') | (df.prefix == 'gpd_SE_graspnet_Euler')]\n",
    "df_table = df_table.groupby(['prefix', 'cat', 'idx']).agg({'init_scores': [np.mean],\n",
    "                                    'final_scores': [np.mean],\n",
    "                                     'init_success': [np.sum],\n",
    "                                     'success': [np.sum]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3cf6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7e833454dbcc567204dfd0d096adbbbc47224b04b8ce44f1671c333a006e7f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
