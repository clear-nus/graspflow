{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e251e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f493c122ad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from graspflow_classifiers import S_classifier, C_classifier\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3794039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = S_classifier(path_to_model='saved_models/evaluator/165228576343/100.pt', device='cpu')\n",
    "C = C_classifier(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165c91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.rand([4,3], requires_grad=True)\n",
    "r=torch.rand([4,3], requires_grad=True)\n",
    "pc = torch.rand([4,1024,3])\n",
    "pc_mean = torch.rand([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ecd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.nn.Parameter(t.clone())\n",
    "r=torch.nn.Parameter(r.clone())\n",
    "optimizer = torch.optim.SGD([{'params': [t]}], lr=1, maximize=True)\n",
    "optimizer2 = torch.optim.SGD([{'params': [r]}], lr=1, maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac12218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(losses, t, r):\n",
    "    t_init = t.clone()\n",
    "    r_init = r.clone()\n",
    "    t_grads = []\n",
    "    r_grads = []\n",
    "    for loss in losses:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(torch.ones_like(loss), retain_graph=True)\n",
    "        #optimizer.step()\n",
    "        #optimizer2.step()\n",
    "        \n",
    "         # extract delta change\n",
    "        delta_t = optimizer.param_groups[0]['params'][0].detach().clone() - t_init\n",
    "        delta_r = optimizer2.param_groups[0]['params'][0].detach().clone() - r_init\n",
    "        \n",
    "        delta_t = optimizer.param_groups[0]['params'][0].detach().clone() - t_init\n",
    "        delta_r = optimizer2.param_groups[0]['params'][0].detach().clone() - r_init\n",
    "        \n",
    "        \n",
    "        t_grads.append(delta_t)\n",
    "        r_grads.append(delta_r)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            optimizer.param_groups[0]['params'][0].copy_(t_init)\n",
    "            optimizer2.param_groups[0]['params'][0].copy_(r_init)\n",
    "        \n",
    "    # make update\n",
    "    t_new = t_init.clone()\n",
    "    r_new = r_init.clone()\n",
    "\n",
    "    for idx, classifier in enumerate('SC'):\n",
    "        t_new = t_new + 0.1*t_grads[idx]\n",
    "        r_new = r_new + 0.1*r_grads[idx]\n",
    "        \n",
    "    # assign to params\n",
    "    with torch.no_grad():\n",
    "        optimizer.param_groups[0]['params'][0].copy_(t_new)\n",
    "        optimizer2.param_groups[0]['params'][0].copy_(r_new)\n",
    "        \n",
    "    return t_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfc7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9015f570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in SinBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1867703/891564428.py\", line 7, in <module>\n",
      "    logit2, _ = S.forward(t=t, r=r, pc=pc, grasp_space='Euler')\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow/graspflow_classifiers.py\", line 35, in forward\n",
      "    logit, _, _  = self.evaluator.forward_with_eulers(r, t, pc)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow/networks/models.py\", line 275, in forward_with_eulers\n",
      "    gripper_pc = utils.control_points_from_rot_and_trans(eulers, trans, config_path=self.control_point_path)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow/networks/utils.py\", line 276, in control_points_from_rot_and_trans\n",
      "    rot = quaternion.euler2matrix(grasp_eulers,\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow/networks/quaternion.py\", line 496, in euler2matrix\n",
      "    matrices = [\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow/networks/quaternion.py\", line 497, in <listcomp>\n",
      "    axis_angle_rotation(c, e)\n",
      "  File \"/home/tasbolat/some_python_examples/graspflow_models/graspflow/networks/quaternion.py\", line 461, in axis_angle_rotation\n",
      "    sin = torch.sin(angle)\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:102.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Output 2 of UnbindBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlogsigmoid(logit2)\n\u001b[1;32m     12\u001b[0m losses \u001b[38;5;241m=\u001b[39m [loss1, loss2]\n\u001b[0;32m---> 13\u001b[0m t_init \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 8\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(losses, t, r)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m losses:\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#optimizer.step()\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#optimizer2.step()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m      \u001b[38;5;66;03m# extract delta change\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     delta_t \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;241m-\u001b[39m t_init\n",
      "File \u001b[0;32m~/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/functorch/_src/monkey_patching.py:77\u001b[0m, in \u001b[0;36m_backward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mare_transforms_active():\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward() called inside a functorch transform. This is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported, please use functorch.grad or functorch.vjp instead \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor call backward() outside of functorch transforms.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_old_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/some_python_examples/graspflow_models/graspflow_venv/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Output 2 of UnbindBackward0 is a view and its base or another view of its base has been modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one."
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    \n",
    "    print(pc.shape)\n",
    "    print(pc_mean.shape)\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "\n",
    "        logit2, _ = S.forward(t=t, r=r, pc=pc, grasp_space='Euler')\n",
    "        logit1, _ = C.forward(t=t, r=r, pc_mean=pc_mean, grasp_space='Euler')\n",
    "\n",
    "        loss1 = torch.nn.functional.logsigmoid(logit1)\n",
    "        loss2 = torch.nn.functional.logsigmoid(logit2)\n",
    "        losses = [loss1, loss2]\n",
    "        t_init = step(losses, t, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43127a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d1a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4732f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x,y):\n",
    "    return 2*x**2 + 3*y**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08993a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x,y):\n",
    "    return x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169cf8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([1.0])\n",
    "y = torch.FloatTensor([1.0])\n",
    "\n",
    "x = torch.nn.Parameter(x.clone())\n",
    "y = torch.nn.Parameter(y.clone())\n",
    "\n",
    "optimizer = torch.optim.SGD([{'params':[x]},{'params':[y]}], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b850b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(losses, t, r):\n",
    "    t_init = t.clone()\n",
    "    r_init = r.clone()\n",
    "    t_grads = []\n",
    "    r_grads = []\n",
    "    for loss in losses:\n",
    "        print('start')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(torch.ones_like(loss), retain_graph=True)\n",
    "        \n",
    "        print(optimizer.param_groups[0]['params'][0])\n",
    "        optimizer.step()\n",
    "        print(optimizer.param_groups[0]['params'][0])\n",
    "         # extract delta change\n",
    "        delta_t = optimizer.param_groups[0]['params'][0].detach().clone() - t_init\n",
    "        delta_r = optimizer.param_groups[1]['params'][0].detach().clone() - r_init\n",
    "\n",
    "        t_grads.append(delta_t)\n",
    "        r_grads.append(delta_r)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            optimizer.param_groups[0]['params'][0].copy_(t_init)\n",
    "            optimizer.param_groups[1]['params'][0].copy_(r_init)\n",
    "        \n",
    "    # make update\n",
    "    t_new = t_init.clone()\n",
    "    r_new = r_init.clone()\n",
    "\n",
    "    for idx, classifier in enumerate('SC'):\n",
    "        t_new = t_new + 0.1*t_grads[idx]\n",
    "        r_new = r_new + 0.1*r_grads[idx]\n",
    "        \n",
    "    # assign to params\n",
    "    with torch.no_grad():\n",
    "        optimizer.param_groups[0]['params'][0].copy_(t_new)\n",
    "        optimizer.param_groups[1]['params'][0].copy_(r_new)\n",
    "        \n",
    "    print(optimizer.param_groups[0]['params'][0])\n",
    "    print('end')    \n",
    "    return t_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "782db2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.5679], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3408], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.5679], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4679], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5352], requires_grad=True)\n",
      "end\n",
      "1\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.5352], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3211], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.5352], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4352], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5038], requires_grad=True)\n",
      "end\n",
      "2\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.5038], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3023], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.5038], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4038], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4736], requires_grad=True)\n",
      "end\n",
      "3\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.4736], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2842], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.4736], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3736], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4447], requires_grad=True)\n",
      "end\n",
      "4\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.4447], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2668], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.4447], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3447], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4169], requires_grad=True)\n",
      "end\n",
      "5\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.4169], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2501], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.4169], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3169], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3902], requires_grad=True)\n",
      "end\n",
      "6\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3902], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2341], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3902], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2902], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3646], requires_grad=True)\n",
      "end\n",
      "7\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3646], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2188], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3646], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2646], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3400], requires_grad=True)\n",
      "end\n",
      "8\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3400], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2040], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3400], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2400], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3164], requires_grad=True)\n",
      "end\n",
      "9\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3164], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1899], requires_grad=True)\n",
      "start\n",
      "Parameter containing:\n",
      "tensor([0.3164], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2164], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2938], requires_grad=True)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    print(k)\n",
    "    \n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "\n",
    "        logit2 = f2(x,y)\n",
    "        logit1 = f1(x,y)\n",
    "\n",
    "        #loss1 = torch.nn.functional.logsigmoid(logit1)\n",
    "        #loss2 = torch.nn.functional.logsigmoid(logit2)\n",
    "        losses = [logit1, logit2]\n",
    "        t_init = step(losses, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "919607bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_classifiers = [''.join(l) for i in range(len(classifiers)) for l in itertools.combinations(classifiers, i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fff73174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6324c2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'C',\n",
       " 'E',\n",
       " 'T',\n",
       " 'N',\n",
       " 'SC',\n",
       " 'SE',\n",
       " 'ST',\n",
       " 'SN',\n",
       " 'CS',\n",
       " 'CE',\n",
       " 'CT',\n",
       " 'CN',\n",
       " 'ES',\n",
       " 'EC',\n",
       " 'ET',\n",
       " 'EN',\n",
       " 'TS',\n",
       " 'TC',\n",
       " 'TE',\n",
       " 'TN',\n",
       " 'NS',\n",
       " 'NC',\n",
       " 'NE',\n",
       " 'NT',\n",
       " 'SCE',\n",
       " 'SCT',\n",
       " 'SCN',\n",
       " 'SEC',\n",
       " 'SET',\n",
       " 'SEN',\n",
       " 'STC',\n",
       " 'STE',\n",
       " 'STN',\n",
       " 'SNC',\n",
       " 'SNE',\n",
       " 'SNT',\n",
       " 'CSE',\n",
       " 'CST',\n",
       " 'CSN',\n",
       " 'CES',\n",
       " 'CET',\n",
       " 'CEN',\n",
       " 'CTS',\n",
       " 'CTE',\n",
       " 'CTN',\n",
       " 'CNS',\n",
       " 'CNE',\n",
       " 'CNT',\n",
       " 'ESC',\n",
       " 'EST',\n",
       " 'ESN',\n",
       " 'ECS',\n",
       " 'ECT',\n",
       " 'ECN',\n",
       " 'ETS',\n",
       " 'ETC',\n",
       " 'ETN',\n",
       " 'ENS',\n",
       " 'ENC',\n",
       " 'ENT',\n",
       " 'TSC',\n",
       " 'TSE',\n",
       " 'TSN',\n",
       " 'TCS',\n",
       " 'TCE',\n",
       " 'TCN',\n",
       " 'TES',\n",
       " 'TEC',\n",
       " 'TEN',\n",
       " 'TNS',\n",
       " 'TNC',\n",
       " 'TNE',\n",
       " 'NSC',\n",
       " 'NSE',\n",
       " 'NST',\n",
       " 'NCS',\n",
       " 'NCE',\n",
       " 'NCT',\n",
       " 'NES',\n",
       " 'NEC',\n",
       " 'NET',\n",
       " 'NTS',\n",
       " 'NTC',\n",
       " 'NTE',\n",
       " 'SCET',\n",
       " 'SCEN',\n",
       " 'SCTE',\n",
       " 'SCTN',\n",
       " 'SCNE',\n",
       " 'SCNT',\n",
       " 'SECT',\n",
       " 'SECN',\n",
       " 'SETC',\n",
       " 'SETN',\n",
       " 'SENC',\n",
       " 'SENT',\n",
       " 'STCE',\n",
       " 'STCN',\n",
       " 'STEC',\n",
       " 'STEN',\n",
       " 'STNC',\n",
       " 'STNE',\n",
       " 'SNCE',\n",
       " 'SNCT',\n",
       " 'SNEC',\n",
       " 'SNET',\n",
       " 'SNTC',\n",
       " 'SNTE',\n",
       " 'CSET',\n",
       " 'CSEN',\n",
       " 'CSTE',\n",
       " 'CSTN',\n",
       " 'CSNE',\n",
       " 'CSNT',\n",
       " 'CEST',\n",
       " 'CESN',\n",
       " 'CETS',\n",
       " 'CETN',\n",
       " 'CENS',\n",
       " 'CENT',\n",
       " 'CTSE',\n",
       " 'CTSN',\n",
       " 'CTES',\n",
       " 'CTEN',\n",
       " 'CTNS',\n",
       " 'CTNE',\n",
       " 'CNSE',\n",
       " 'CNST',\n",
       " 'CNES',\n",
       " 'CNET',\n",
       " 'CNTS',\n",
       " 'CNTE',\n",
       " 'ESCT',\n",
       " 'ESCN',\n",
       " 'ESTC',\n",
       " 'ESTN',\n",
       " 'ESNC',\n",
       " 'ESNT',\n",
       " 'ECST',\n",
       " 'ECSN',\n",
       " 'ECTS',\n",
       " 'ECTN',\n",
       " 'ECNS',\n",
       " 'ECNT',\n",
       " 'ETSC',\n",
       " 'ETSN',\n",
       " 'ETCS',\n",
       " 'ETCN',\n",
       " 'ETNS',\n",
       " 'ETNC',\n",
       " 'ENSC',\n",
       " 'ENST',\n",
       " 'ENCS',\n",
       " 'ENCT',\n",
       " 'ENTS',\n",
       " 'ENTC',\n",
       " 'TSCE',\n",
       " 'TSCN',\n",
       " 'TSEC',\n",
       " 'TSEN',\n",
       " 'TSNC',\n",
       " 'TSNE',\n",
       " 'TCSE',\n",
       " 'TCSN',\n",
       " 'TCES',\n",
       " 'TCEN',\n",
       " 'TCNS',\n",
       " 'TCNE',\n",
       " 'TESC',\n",
       " 'TESN',\n",
       " 'TECS',\n",
       " 'TECN',\n",
       " 'TENS',\n",
       " 'TENC',\n",
       " 'TNSC',\n",
       " 'TNSE',\n",
       " 'TNCS',\n",
       " 'TNCE',\n",
       " 'TNES',\n",
       " 'TNEC',\n",
       " 'NSCE',\n",
       " 'NSCT',\n",
       " 'NSEC',\n",
       " 'NSET',\n",
       " 'NSTC',\n",
       " 'NSTE',\n",
       " 'NCSE',\n",
       " 'NCST',\n",
       " 'NCES',\n",
       " 'NCET',\n",
       " 'NCTS',\n",
       " 'NCTE',\n",
       " 'NESC',\n",
       " 'NEST',\n",
       " 'NECS',\n",
       " 'NECT',\n",
       " 'NETS',\n",
       " 'NETC',\n",
       " 'NTSC',\n",
       " 'NTSE',\n",
       " 'NTCS',\n",
       " 'NTCE',\n",
       " 'NTES',\n",
       " 'NTEC',\n",
       " 'SCETN',\n",
       " 'SCENT',\n",
       " 'SCTEN',\n",
       " 'SCTNE',\n",
       " 'SCNET',\n",
       " 'SCNTE',\n",
       " 'SECTN',\n",
       " 'SECNT',\n",
       " 'SETCN',\n",
       " 'SETNC',\n",
       " 'SENCT',\n",
       " 'SENTC',\n",
       " 'STCEN',\n",
       " 'STCNE',\n",
       " 'STECN',\n",
       " 'STENC',\n",
       " 'STNCE',\n",
       " 'STNEC',\n",
       " 'SNCET',\n",
       " 'SNCTE',\n",
       " 'SNECT',\n",
       " 'SNETC',\n",
       " 'SNTCE',\n",
       " 'SNTEC',\n",
       " 'CSETN',\n",
       " 'CSENT',\n",
       " 'CSTEN',\n",
       " 'CSTNE',\n",
       " 'CSNET',\n",
       " 'CSNTE',\n",
       " 'CESTN',\n",
       " 'CESNT',\n",
       " 'CETSN',\n",
       " 'CETNS',\n",
       " 'CENST',\n",
       " 'CENTS',\n",
       " 'CTSEN',\n",
       " 'CTSNE',\n",
       " 'CTESN',\n",
       " 'CTENS',\n",
       " 'CTNSE',\n",
       " 'CTNES',\n",
       " 'CNSET',\n",
       " 'CNSTE',\n",
       " 'CNEST',\n",
       " 'CNETS',\n",
       " 'CNTSE',\n",
       " 'CNTES',\n",
       " 'ESCTN',\n",
       " 'ESCNT',\n",
       " 'ESTCN',\n",
       " 'ESTNC',\n",
       " 'ESNCT',\n",
       " 'ESNTC',\n",
       " 'ECSTN',\n",
       " 'ECSNT',\n",
       " 'ECTSN',\n",
       " 'ECTNS',\n",
       " 'ECNST',\n",
       " 'ECNTS',\n",
       " 'ETSCN',\n",
       " 'ETSNC',\n",
       " 'ETCSN',\n",
       " 'ETCNS',\n",
       " 'ETNSC',\n",
       " 'ETNCS',\n",
       " 'ENSCT',\n",
       " 'ENSTC',\n",
       " 'ENCST',\n",
       " 'ENCTS',\n",
       " 'ENTSC',\n",
       " 'ENTCS',\n",
       " 'TSCEN',\n",
       " 'TSCNE',\n",
       " 'TSECN',\n",
       " 'TSENC',\n",
       " 'TSNCE',\n",
       " 'TSNEC',\n",
       " 'TCSEN',\n",
       " 'TCSNE',\n",
       " 'TCESN',\n",
       " 'TCENS',\n",
       " 'TCNSE',\n",
       " 'TCNES',\n",
       " 'TESCN',\n",
       " 'TESNC',\n",
       " 'TECSN',\n",
       " 'TECNS',\n",
       " 'TENSC',\n",
       " 'TENCS',\n",
       " 'TNSCE',\n",
       " 'TNSEC',\n",
       " 'TNCSE',\n",
       " 'TNCES',\n",
       " 'TNESC',\n",
       " 'TNECS',\n",
       " 'NSCET',\n",
       " 'NSCTE',\n",
       " 'NSECT',\n",
       " 'NSETC',\n",
       " 'NSTCE',\n",
       " 'NSTEC',\n",
       " 'NCSET',\n",
       " 'NCSTE',\n",
       " 'NCEST',\n",
       " 'NCETS',\n",
       " 'NCTSE',\n",
       " 'NCTES',\n",
       " 'NESCT',\n",
       " 'NESTC',\n",
       " 'NECST',\n",
       " 'NECTS',\n",
       " 'NETSC',\n",
       " 'NETCS',\n",
       " 'NTSCE',\n",
       " 'NTSEC',\n",
       " 'NTCSE',\n",
       " 'NTCES',\n",
       " 'NTESC',\n",
       " 'NTECS']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaacd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
